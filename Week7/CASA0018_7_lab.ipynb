{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CASA0018_7_lab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMNOMuM6uZhUgORrK7ASdUq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/djdunc/casa0018/blob/main/Week7/CASA0018_7_lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zHy1gydhMJF"
      },
      "source": [
        "# **Deep Learning for Sensors Networks**\n",
        "# Week 7 - Lab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_Ju0KZBiFF8"
      },
      "source": [
        "This is your chance to try out RNNs on a real data set (light-400.csv). The data set contains 400 data points recorded by an indoor light sensor (light dependent resistor) over a period of about 20 days. \n",
        "\n",
        "The data set can be found here:\n",
        "https://github.com/djdunc/casa0018/tree/main/Week7\n",
        "\n",
        "Download it to your local machine.\n",
        "\n",
        "To get you started I've include some code to load the data into a Python dataframe and split the data into train and validate sets.\n",
        "\n",
        "Your tasks is to build both a vanilla RNN and LSTM, train them on the data set and use them to perform forecasting. The tasks are outlined in more detail later in the notebook.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHSsdcvgh7AX"
      },
      "source": [
        "# Set up the imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS2gSKQlhae8"
      },
      "source": [
        "import io\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator # Generates batches for sequence data\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from google.colab import files\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvp9_ZSJilBc"
      },
      "source": [
        "# Load sensor data from csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwM7-826ivXc"
      },
      "source": [
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBWXgIJ-oU-S"
      },
      "source": [
        "# Load into a dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfXvMqwsodAj"
      },
      "source": [
        "df = pd.read_csv('light-400.csv')\n",
        "print(len(df))\n",
        "print(df)\n",
        "df.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maLwEBXpoysp"
      },
      "source": [
        "# Split into Train and Validate sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urmhbSYwo4Rg"
      },
      "source": [
        "print(len(df)) \n",
        "val_percent = 0.1   # 10 percent of data\n",
        "val_point = np.round(len(df)*val_percent) \n",
        "val_index = int(len(df) - val_point)\n",
        "train = df.iloc[:val_index]\n",
        "val = df.iloc[val_index:]\n",
        "\n",
        "print(len(train))\n",
        "print(len(val))\n",
        "\n",
        "plt.plot(train)\n",
        "plt.plot(val)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEkJ5f1npSXa"
      },
      "source": [
        "# Your Tasks\n",
        "\n",
        "*   Build and train a vanilla RNN\n",
        "*   Check your model against the validation data set\n",
        "*   Use your model to forecast 40 steps into the future\n",
        "\n",
        "Repeat the above steps for a LSTM \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XokT2ZKc4Pv"
      },
      "source": [
        "# Things to explore\n",
        "\n",
        "*  Batch size - Try varying the batch size to, for example, 1 and 10. How does batch size affect model accuracy and training time? Why?\n",
        "\n",
        "*  Number of RNN layers - what happens if you add a second recurrent layer to your model? Here is the code to do this for a vanilla RNN. The code for a LSTM is similar.\n",
        "```\n",
        "rnn_model.add(SimpleRNN(output_space, return_sequences=True, input_shape = (length , n_features)))\n",
        "rnn_model.add(SimpleRNN(output_space))\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}